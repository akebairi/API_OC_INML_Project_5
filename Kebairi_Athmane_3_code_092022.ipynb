{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb04448d-9cb2-4f56-b174-24592edab520",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h1>Projet_OC_05 : Catégorisez automatiquement des questions (API)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8462dd8-d1e0-42be-82cb-7d550ad72db5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sommaire :\n",
    "\n",
    "**Partie 1 : Configuration du notebook**\n",
    "\n",
    " - <a href=\"#C11\">P1.1 : Chargement des librairies </a>\n",
    " - <a href=\"#C12\">P1.2 : Fonctions </a>\n",
    " - <a href=\"#C13\">P1.3 : Chargement des données</a>\n",
    " \n",
    "**Partie 2 : Représentation de données**\n",
    "\n",
    " - <a href=\"#C21\">P2.1 : Structure de données </a>\n",
    " - <a href=\"#C22\">P2.2 : NaN et doublons </a>\n",
    " - <a href=\"#C23\">P2.3 : Inspection de données </a> \n",
    " \n",
    "**Partie 3 : Analyse de données**\n",
    "\n",
    " - <a href=\"#C31\">P3.1 : Structure de données </a>\n",
    " - <a href=\"#C32\">P3.2 : Nettoyage de données </a>\n",
    " - <a href=\"#C33\">P3.3 : Visualisation par wordcloud </a>\n",
    " \n",
    "  \n",
    "**Partie 4 : Enregistrement de données**\n",
    "\n",
    " - <a href=\"#C41\">P4.1 : nregistrement de données </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b236f59f-6ba4-4943-bdc9-2e710b5b1b42",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<h1>Partie 1 : Configuration du notebook</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcfa272-9ea7-4a7d-9a47-b2d7614c78b9",
   "metadata": {},
   "source": [
    "# <a name=\"C11\"> P1.1 : Chargement des librairies </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f7e1fe1-b89b-41cc-b419-03904c8f9ef8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, wordpunct_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import spacy\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression, Perceptron\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import hamming_loss, jaccard_score\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import joblib\n",
    "from mlflow.models.signature import infer_signature\n",
    "import mlflow.sklearn \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beacdf4e-5f6b-46d7-809b-68e60115a160",
   "metadata": {},
   "source": [
    "**La liste des librairies ci-dessus sont chargées.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71462af7-6fb3-49c0-92f5-ce91887424da",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <a name=\"C12\"> P1.2 : Fonctions </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "962a81f4-2747-46cb-9137-11c020b43977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags_process(sentence, most_freq_tags):\n",
    "    \n",
    "    sentence_process = (sentence.replace('<', ' ').replace('>', ' ').replace('/', ' ').strip()).split()\n",
    "    \n",
    "    sentence_filter = [word for word in sentence_process if word in most_freq_tags]                \n",
    "    \n",
    "    if sentence_filter:\n",
    "        return ' '.join(sentence_filter)\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d21b4b1-5066-495e-a22d-283a7e068ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_ponc_process(sentence):\n",
    "    \n",
    "    return sentence.replace('c#', 'csharp').replace('c++', 'cplusplus').replace('.net', 'dotnet').replace('objective-c', 'objectivec').replace('ruby-on-rails', 'rubyonrails')\\\n",
    "                .replace('sql-server', 'sqlserver').replace('node.js', 'nodedotjs').replace('aspdotnet-mvc', 'aspdotnetmvc').replace('visual-studio', 'visualstudio').replace('visual studio', 'visualstudio')\\\n",
    "                .replace('unit-testing', 'unittesting').replace('cocoa-touch', 'cocoatouch').replace('python-3.x', 'python3x').replace('entity-framework', 'entityframework')\\\n",
    "                .replace('language-agnostic', 'languageagnostic').replace('amazon-web-services', 'amazonwebservices').replace('google-chrome', 'googlechrome').replace('user-interface', 'userinterface')\\\n",
    "                .replace('design-patterns', 'designpatterns').replace('version-control', 'versioncontrol').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "93d0fe11-ebea-4139-9ecd-36ee5513bb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TXTProcesser(TransformerMixin, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, stop_words, authorized_pos, no_pos_tag_list, no_lem_stem_list, nlp, embed):\n",
    "        \n",
    "        self.stop_words = stop_words\n",
    "        self.authorized_pos = authorized_pos\n",
    "        self.no_pos_tag_list = no_pos_tag_list\n",
    "        self.no_lem_stem_list = no_lem_stem_list\n",
    "        self.nlp = nlp\n",
    "        self.embed = embed\n",
    "    \n",
    "    def fit(self, X, Y=None):\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, Y=None):\n",
    "        \n",
    "        X_clean = []\n",
    "        \n",
    "        if isinstance(X, list):\n",
    "            for x in X:\n",
    "                X_clean.append(self.txt_clean(x))            \n",
    "    \n",
    "            return self.txt_use_feature(X_clean)\n",
    "            \n",
    "        else:        \n",
    "            \n",
    "            for x in [X]*10:\n",
    "                X_clean.append(self.txt_clean(x))            \n",
    "\n",
    "            return [self.txt_use_feature(X_clean)[0]]\n",
    "    \n",
    "    def txt_clean(self, X, Y=None):\n",
    "  \n",
    "        sentence_lower = X.lower()\n",
    "    \n",
    "        sentence_no_html_raw = BeautifulSoup(sentence_lower, \"html.parser\")\n",
    "\n",
    "        for data in sentence_no_html_raw(['style', 'script', 'code', 'a']):\n",
    "            # Remove tags\n",
    "            data.decompose()\n",
    "\n",
    "        sentence_no_html = ' '.join(sentence_no_html_raw.stripped_strings)\n",
    "\n",
    "        sentence_no_abb = sentence_no_html.replace(\"what's\", \"what is \").replace(\"\\'ve\", \" have \").replace(\"can't\", \"can not \").replace(\"n't\", \" not \").replace(\"i'm\", \"i am \")\\\n",
    "                           .replace(\"\\'re\", \" are \").replace(\"\\'d\", \" would \").replace(\"\\'ll\", \" will \").replace(\"\\'scuse\", \" excuse \").replace(' vs ', ' ').replace('difference between', ' ')\n",
    "\n",
    "        sentence_no_abb_trans = sentence_no_abb.replace('c#', 'csharp').replace('c++', 'cplusplus').replace('.net', 'dotnet').replace('objective-c', 'objectivec').replace('ruby-on-rails', 'rubyonrails')\\\n",
    "                .replace('sql-server', 'sqlserver').replace('node.js', 'nodedotjs').replace('aspdotnet-mvc', 'aspdotnetmvc').replace('visual-studio', 'visualstudio').replace('visual studio', 'visualstudio')\\\n",
    "                .replace('unit-testing', 'unittesting').replace('cocoa-touch', 'cocoatouch').replace('python-3.x', 'python3x').replace('entity-framework', 'entityframework')\\\n",
    "                .replace('language-agnostic', 'languageagnostic').replace('amazon-web-services', 'amazonwebservices').replace('google-chrome', 'googlechrome').replace('user-interface', 'userinterface')\\\n",
    "                .replace('design-patterns', 'designpatterns').replace('version-control', 'versioncontrol').strip()\n",
    "\n",
    "        sentence_no_new_line = re.sub(r'\\n', ' ', sentence_no_abb_trans)\n",
    "\n",
    "        translator = str.maketrans(dict.fromkeys(string.punctuation, ' '))\n",
    "        sentence_no_caracter = sentence_no_new_line.translate(translator)\n",
    "\n",
    "        sentence_no_stopwords = ' '.join([word for word in sentence_no_caracter.split() if word not in self.stop_words])\n",
    "\n",
    "        sentence_tokens =  [token.text for token in self.nlp(sentence_no_stopwords) if token.tag_ in self.authorized_pos and len(token.text)>=3 or token.text in self.no_pos_tag_list] \n",
    "\n",
    "\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lem_or_stem_tokens = [lemmatizer.lemmatize(word) if word not in self.no_lem_stem_list else word for word in sentence_tokens]\n",
    "\n",
    "\n",
    "        final_sentence = ' '.join(sentence_tokens).replace('csharp', 'c#').replace('cplusplus', 'c++').replace('dotnet', '.net').replace('objectivec', 'objective-c').replace('rubyonrails', 'ruby-on-rails')\\\n",
    "                .replace('sqlserver', 'sql-server').replace('nodedotjs', 'node.js').replace('aspdotnetmvc', 'aspdotnet-mvc').replace('visualstudio', 'visual-studio')\\\n",
    "                .replace('unittesting', 'unit-testing').replace('cocoatouch', 'cocoa-touch').replace('python3x', 'python-3.x').replace('entityframework', 'entity-framework')\\\n",
    "                .replace('languageagnostic', 'language-agnostic').replace('amazonwebservices', 'amazon-web-services').replace('googlechrome', 'google-chrome').replace('userinterface', 'user-interface')\\\n",
    "                .replace('designpatterns', 'design-patterns').replace('versioncontrol', 'version-control').strip()\n",
    "\n",
    "        return final_sentence  \n",
    "    \n",
    "    def txt_use_feature(self, X, Y=None):\n",
    "        \n",
    "        batch_size = 8\n",
    "        \n",
    "        for step in range(len(X)//batch_size) :\n",
    "            idx = step*batch_size\n",
    "            feat = self.embed(X[idx:idx+batch_size])\n",
    "\n",
    "            if step ==0 :\n",
    "                features = feat\n",
    "            else :\n",
    "                features = np.concatenate((features,feat))\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c14ccb1d-babf-4c60-a2f0-145258a8b59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TXTModel(TransformerMixin, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, clf, ml_binarizer, nmp):\n",
    "        self.clf = clf\n",
    "        self.ml_binarizer = ml_binarizer\n",
    "        self.nmp = nmp\n",
    "        \n",
    "    def transform(self, Y):\n",
    "        \n",
    "        return self.ml_binarizer.transform(Y) \n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        self.ml_binarizer.fit(Y)\n",
    "        self.clf.fit(X, self.ml_binarizer.transform(Y))\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \n",
    "        return self.clf.predict(X)\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "\n",
    "        dfun = self.clf.decision_function(X)\n",
    "        most_common_idx = self.nmp.argsort(dfun)[:, -5:]\n",
    "        return self.classes_(most_common_idx)\n",
    "        \n",
    "    def inverse_transform(self, Yt):\n",
    "        \n",
    "        return self.ml_binarizer.inverse_transform(Yt)      \n",
    "    \n",
    "    def classes_(self, Y_idx):\n",
    "        \n",
    "        return self.ml_binarizer.classes_[Y_idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b238cb73-68e7-4719-86f7-abfaac666530",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <a name=\"C13\"> P1.3 : Chargement des données </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58ff71e9-3bcd-4cd3-9d03-a1a9e3fd4b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Data size: (99997, 3)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Find Mime type of file or url using php for al...</td>\n",
       "      <td>&lt;p&gt;Hi I am looking for best way to find out mi...</td>\n",
       "      <td>&lt;php&gt;&lt;amazon-web-services&gt;&lt;mime-types&gt;&lt;content...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>native zlib inflate/deflate for swift3 on iOS</td>\n",
       "      <td>&lt;p&gt;I'd like to be able to inflate/deflate Swif...</td>\n",
       "      <td>&lt;ios&gt;&lt;swift&gt;&lt;swift3&gt;&lt;zlib&gt;&lt;swift-data&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>`Sudo pip install matplotlib` fails to find fr...</td>\n",
       "      <td>&lt;p&gt;I already have &lt;code&gt;matplotlib-1.2.1&lt;/code...</td>\n",
       "      <td>&lt;python&gt;&lt;numpy&gt;&lt;matplotlib&gt;&lt;homebrew&gt;&lt;osx-mave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Serialization in C# without using file system</td>\n",
       "      <td>&lt;p&gt;I have a simple 2D array of strings and I w...</td>\n",
       "      <td>&lt;c#&gt;&lt;sharepoint&gt;&lt;serialization&gt;&lt;moss&gt;&lt;wss&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do I prevent IIS from compiling website?</td>\n",
       "      <td>&lt;p&gt;I have an ASP .NET web application which on...</td>\n",
       "      <td>&lt;asp.net&gt;&lt;performance&gt;&lt;web-services&gt;&lt;iis&gt;&lt;asmx&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Find Mime type of file or url using php for al...   \n",
       "1      native zlib inflate/deflate for swift3 on iOS   \n",
       "2  `Sudo pip install matplotlib` fails to find fr...   \n",
       "3      Serialization in C# without using file system   \n",
       "4       How do I prevent IIS from compiling website?   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <p>Hi I am looking for best way to find out mi...   \n",
       "1  <p>I'd like to be able to inflate/deflate Swif...   \n",
       "2  <p>I already have <code>matplotlib-1.2.1</code...   \n",
       "3  <p>I have a simple 2D array of strings and I w...   \n",
       "4  <p>I have an ASP .NET web application which on...   \n",
       "\n",
       "                                                Tags  \n",
       "0  <php><amazon-web-services><mime-types><content...  \n",
       "1             <ios><swift><swift3><zlib><swift-data>  \n",
       "2  <python><numpy><matplotlib><homebrew><osx-mave...  \n",
       "3         <c#><sharepoint><serialization><moss><wss>  \n",
       "4    <asp.net><performance><web-services><iis><asmx>  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_txt_data = pd.read_csv('data.csv')\n",
    "raw_txt_data = raw_txt_data.select_dtypes(include=object)\n",
    "raw_txt_data.dropna(inplace=True)\n",
    "\n",
    "print('-'*150)\n",
    "print('Data size:', raw_txt_data.shape)\n",
    "print('-'*150)\n",
    "raw_txt_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2fce1b45-3b8e-4fff-8d74-02c10b557ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_val = 50\n",
    "all_tags = ' '.join(raw_txt_data.Tags.apply(lambda sentence: sentence.replace('<', ' ').replace('>', ' ')).tolist()).split()\n",
    "unique_tags = list(set(all_tags))\n",
    "keywords = nltk.FreqDist(all_tags)\n",
    "most_common_tags = [word[0] for word in keywords.most_common(most_common_val)]\n",
    "\n",
    "raw_txt_data['Tags'] = raw_txt_data.Tags.apply(lambda sentence: tags_process(sentence, most_common_tags))\n",
    "raw_txt_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "86e92540-6ba9-4009-a636-baade5686256",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "authorized_pos = ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "no_pos_tag_list = tag_ponc_process(' '.join(most_common_tags)).split()\n",
    "no_lem_stem_list = tag_ponc_process(' '.join(most_common_tags)).split()\n",
    "stop_words = list(set(stopwords.words('english'))) + \\\n",
    "                ['[', ']', ',', '.', ':', '?', '(', ')']\n",
    "stop_words.extend(['good', 'idea', 'solution', 'issue', 'problem', 'way', 'example', 'case', 'question', 'questions', 'something', 'everything',\n",
    "                   'anything', 'thing', 'things', 'answer', 'thank', 'thanks', 'none', 'end', 'anyone', 'test', 'lot', 'one', 'someone', 'help'])\n",
    "\n",
    "\n",
    "clf = OneVsRestClassifier(LinearSVC())\n",
    "ml_binarizer = MultiLabelBinarizer()\n",
    "nmp = np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5e835549-e585-45f4-b39f-c2da8fead63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_txt_data.sample(frac=0.1)\n",
    "\n",
    "X = (data.Title + ' ' + data.Body).tolist()\n",
    "\n",
    "y = data.Tags\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1) \n",
    "\n",
    "idx_norm = 8\n",
    "\n",
    "X_train = X_train[:(len(X_train)//idx_norm)*idx_norm]\n",
    "X_test = X_test[:(len(X_test)//idx_norm)*idx_norm]\n",
    "y_train = y_train[:(len(y_train)//idx_norm)*idx_norm]\n",
    "y_test = y_test[:(len(y_test)//idx_norm)*idx_norm]\n",
    "\n",
    "y_train_list = y_train.apply(lambda x: x.split()).tolist()\n",
    "y_test_list = y_test.apply(lambda x: x.split()).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6de190-8141-4656-9ea8-22dc3c4a6a21",
   "metadata": {},
   "source": [
    "# <a name=\"C21\"> P2.1 : Pipeline </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1b36c426-7a28-4cc4-9f7a-d2dd7739c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('transformer', TXTProcesser(stop_words, authorized_pos, no_pos_tag_list, no_lem_stem_list, nlp, embed)),\n",
    "                 ('model', TXTModel(clf, ml_binarizer, nmp))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e75d2a6b-4f6a-4904-9756-25b21692cc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ME\\anaconda3\\envs\\OC_ML_PRJ_5\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;transformer&#x27;,\n",
       "                 TXTProcesser(authorized_pos=[&#x27;NN&#x27;, &#x27;NNS&#x27;, &#x27;NNP&#x27;, &#x27;NNPS&#x27;],\n",
       "                              embed=&lt;tensorflow.python.saved_model.load.Loader._recreate_base_user_object.&lt;locals&gt;._UserObject object at 0x000001DD93602D60&gt;,\n",
       "                              nlp=&lt;spacy.lang.en.English object at 0x000001DD80EE3790&gt;,\n",
       "                              no_lem_stem_list=[&#x27;csharp&#x27;, &#x27;java&#x27;, &#x27;python&#x27;,\n",
       "                                                &#x27;javascript&#x27;, &#x27;cplusplus&#x27;,\n",
       "                                                &#x27;android&#x27;, &#x27;ios&#x27;, &#x27;do...\n",
       "                                          &#x27;did&#x27;, &#x27;no&#x27;, &#x27;a&#x27;, &#x27;when&#x27;, &#x27;out&#x27;,\n",
       "                                          &quot;hasn&#x27;t&quot;, &#x27;mightn&#x27;, &#x27;our&#x27;, &#x27;s&#x27;, &#x27;ll&#x27;,\n",
       "                                          &#x27;t&#x27;, &#x27;herself&#x27;, &#x27;hers&#x27;, &#x27;will&#x27;, &#x27;m&#x27;,\n",
       "                                          &#x27;those&#x27;, &#x27;for&#x27;, &#x27;again&#x27;, &#x27;below&#x27;,\n",
       "                                          &#x27;few&#x27;, &quot;needn&#x27;t&quot;, ...])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 TXTModel(clf=OneVsRestClassifier(estimator=LinearSVC()),\n",
       "                          ml_binarizer=MultiLabelBinarizer(),\n",
       "                          nmp=&lt;module &#x27;numpy&#x27; from &#x27;C:\\\\Users\\\\ME\\\\anaconda3\\\\envs\\\\OC_ML_PRJ_5\\\\lib\\\\site-packages\\\\numpy\\\\__init__.py&#x27;&gt;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;transformer&#x27;,\n",
       "                 TXTProcesser(authorized_pos=[&#x27;NN&#x27;, &#x27;NNS&#x27;, &#x27;NNP&#x27;, &#x27;NNPS&#x27;],\n",
       "                              embed=&lt;tensorflow.python.saved_model.load.Loader._recreate_base_user_object.&lt;locals&gt;._UserObject object at 0x000001DD93602D60&gt;,\n",
       "                              nlp=&lt;spacy.lang.en.English object at 0x000001DD80EE3790&gt;,\n",
       "                              no_lem_stem_list=[&#x27;csharp&#x27;, &#x27;java&#x27;, &#x27;python&#x27;,\n",
       "                                                &#x27;javascript&#x27;, &#x27;cplusplus&#x27;,\n",
       "                                                &#x27;android&#x27;, &#x27;ios&#x27;, &#x27;do...\n",
       "                                          &#x27;did&#x27;, &#x27;no&#x27;, &#x27;a&#x27;, &#x27;when&#x27;, &#x27;out&#x27;,\n",
       "                                          &quot;hasn&#x27;t&quot;, &#x27;mightn&#x27;, &#x27;our&#x27;, &#x27;s&#x27;, &#x27;ll&#x27;,\n",
       "                                          &#x27;t&#x27;, &#x27;herself&#x27;, &#x27;hers&#x27;, &#x27;will&#x27;, &#x27;m&#x27;,\n",
       "                                          &#x27;those&#x27;, &#x27;for&#x27;, &#x27;again&#x27;, &#x27;below&#x27;,\n",
       "                                          &#x27;few&#x27;, &quot;needn&#x27;t&quot;, ...])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 TXTModel(clf=OneVsRestClassifier(estimator=LinearSVC()),\n",
       "                          ml_binarizer=MultiLabelBinarizer(),\n",
       "                          nmp=&lt;module &#x27;numpy&#x27; from &#x27;C:\\\\Users\\\\ME\\\\anaconda3\\\\envs\\\\OC_ML_PRJ_5\\\\lib\\\\site-packages\\\\numpy\\\\__init__.py&#x27;&gt;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TXTProcesser</label><div class=\"sk-toggleable__content\"><pre>TXTProcesser(authorized_pos=[&#x27;NN&#x27;, &#x27;NNS&#x27;, &#x27;NNP&#x27;, &#x27;NNPS&#x27;],\n",
       "             embed=&lt;tensorflow.python.saved_model.load.Loader._recreate_base_user_object.&lt;locals&gt;._UserObject object at 0x000001DD93602D60&gt;,\n",
       "             nlp=&lt;spacy.lang.en.English object at 0x000001DD80EE3790&gt;,\n",
       "             no_lem_stem_list=[&#x27;csharp&#x27;, &#x27;java&#x27;, &#x27;python&#x27;, &#x27;javascript&#x27;,\n",
       "                               &#x27;cplusplus&#x27;, &#x27;android&#x27;, &#x27;ios&#x27;, &#x27;dotnet&#x27;, &#x27;html&#x27;,\n",
       "                               &#x27;php&#x27;, &#x27;jquery&#x27;, &#x27;ob...\n",
       "                              &#x27;css&#x27;, &#x27;sql&#x27;, &#x27;aspdotnet&#x27;, &#x27;linux&#x27;, &#x27;nodedotjs&#x27;,\n",
       "                              &#x27;swift&#x27;, &#x27;performance&#x27;, &#x27;windows&#x27;, &#x27;spring&#x27;,\n",
       "                              &#x27;rubyonrails&#x27;, &#x27;mysql&#x27;, &#x27;xcode&#x27;, &#x27;sqlserver&#x27;,\n",
       "                              &#x27;json&#x27;, &#x27;django&#x27;, &#x27;aspdotnetmvc&#x27;, ...],\n",
       "             stop_words=[&#x27;all&#x27;, &#x27;can&#x27;, &quot;hadn&#x27;t&quot;, &#x27;she&#x27;, &#x27;being&#x27;, &#x27;which&#x27;, &#x27;of&#x27;,\n",
       "                         &quot;don&#x27;t&quot;, &#x27;y&#x27;, &#x27;did&#x27;, &#x27;no&#x27;, &#x27;a&#x27;, &#x27;when&#x27;, &#x27;out&#x27;,\n",
       "                         &quot;hasn&#x27;t&quot;, &#x27;mightn&#x27;, &#x27;our&#x27;, &#x27;s&#x27;, &#x27;ll&#x27;, &#x27;t&#x27;, &#x27;herself&#x27;,\n",
       "                         &#x27;hers&#x27;, &#x27;will&#x27;, &#x27;m&#x27;, &#x27;those&#x27;, &#x27;for&#x27;, &#x27;again&#x27;, &#x27;below&#x27;,\n",
       "                         &#x27;few&#x27;, &quot;needn&#x27;t&quot;, ...])</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">model: TXTModel</label><div class=\"sk-toggleable__content\"><pre>TXTModel(clf=OneVsRestClassifier(estimator=LinearSVC()),\n",
       "         ml_binarizer=MultiLabelBinarizer(),\n",
       "         nmp=&lt;module &#x27;numpy&#x27; from &#x27;C:\\\\Users\\\\ME\\\\anaconda3\\\\envs\\\\OC_ML_PRJ_5\\\\lib\\\\site-packages\\\\numpy\\\\__init__.py&#x27;&gt;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">clf: OneVsRestClassifier</label><div class=\"sk-toggleable__content\"><pre>OneVsRestClassifier(estimator=LinearSVC())</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ml_binarizer: MultiLabelBinarizer</label><div class=\"sk-toggleable__content\"><pre>MultiLabelBinarizer()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiLabelBinarizer</label><div class=\"sk-toggleable__content\"><pre>MultiLabelBinarizer()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('transformer',\n",
       "                 TXTProcesser(authorized_pos=['NN', 'NNS', 'NNP', 'NNPS'],\n",
       "                              embed=<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject object at 0x000001DD93602D60>,\n",
       "                              nlp=<spacy.lang.en.English object at 0x000001DD80EE3790>,\n",
       "                              no_lem_stem_list=['csharp', 'java', 'python',\n",
       "                                                'javascript', 'cplusplus',\n",
       "                                                'android', 'ios', 'do...\n",
       "                                          'did', 'no', 'a', 'when', 'out',\n",
       "                                          \"hasn't\", 'mightn', 'our', 's', 'll',\n",
       "                                          't', 'herself', 'hers', 'will', 'm',\n",
       "                                          'those', 'for', 'again', 'below',\n",
       "                                          'few', \"needn't\", ...])),\n",
       "                ('model',\n",
       "                 TXTModel(clf=OneVsRestClassifier(estimator=LinearSVC()),\n",
       "                          ml_binarizer=MultiLabelBinarizer(),\n",
       "                          nmp=<module 'numpy' from 'C:\\\\Users\\\\ME\\\\anaconda3\\\\envs\\\\OC_ML_PRJ_5\\\\lib\\\\site-packages\\\\numpy\\\\__init__.py'>))])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7c4b97-8c27-4409-a3da-6670bef8bd94",
   "metadata": {},
   "source": [
    "# <a name=\"C22\"> P2.2 : déploiement du pipeline </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "664108c6-4967-4b4d-81d7-04e13b4ec476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pipeline_housing.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump('pipe', 'pipeline_housing.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b865cb2-a7ae-48ae-b448-e9a1338bfb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ME\\AppData\\Local\\Temp\\ipykernel_3556\\1947179035.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  signature = infer_signature(np.array(X_train[:(len(X_train)//10)*10]), np.array(y_train_list[:(len(X_train)//10)*10]))\n"
     ]
    }
   ],
   "source": [
    "signature = infer_signature(np.array(X_train[:(len(X_train)//10)*10]), np.array(y_train_list[:(len(X_train)//10)*10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87c578e7-080c-4a7e-a6d1-6cbf60b667e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "PickleError",
     "evalue": "Can't pickle repeated scalar fields, convert to list first",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPickleError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msklearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmlflow_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\OC_ML_PRJ_5\\lib\\site-packages\\mlflow\\sklearn\\__init__.py:254\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(sk_model, path, conda_env, code_paths, mlflow_model, serialization_format, signature, input_example, pip_requirements, extra_pip_requirements, pyfunc_predict_fn)\u001b[0m\n\u001b[0;32m    252\u001b[0m model_data_subpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m model_data_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, model_data_subpath)\n\u001b[1;32m--> 254\u001b[0m \u001b[43m_save_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43msk_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msk_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_data_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserialization_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserialization_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;66;03m# `PyFuncModel` only works for sklearn models that define a predict function\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(sk_model, pyfunc_predict_fn):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\OC_ML_PRJ_5\\lib\\site-packages\\mlflow\\sklearn\\__init__.py:541\u001b[0m, in \u001b[0;36m_save_model\u001b[1;34m(sk_model, output_path, serialization_format)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m serialization_format \u001b[38;5;241m==\u001b[39m SERIALIZATION_FORMAT_CLOUDPICKLE:\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcloudpickle\u001b[39;00m\n\u001b[1;32m--> 541\u001b[0m     \u001b[43m_dump_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcloudpickle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msk_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m    544\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized serialization format: \u001b[39m\u001b[38;5;132;01m{serialization_format}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    545\u001b[0m             serialization_format\u001b[38;5;241m=\u001b[39mserialization_format\n\u001b[0;32m    546\u001b[0m         ),\n\u001b[0;32m    547\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mINTERNAL_ERROR,\n\u001b[0;32m    548\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\OC_ML_PRJ_5\\lib\\site-packages\\mlflow\\sklearn\\__init__.py:519\u001b[0m, in \u001b[0;36m_dump_model\u001b[1;34m(pickle_lib, sk_model, out)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_dump_model\u001b[39m(pickle_lib, sk_model, out):\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    516\u001b[0m         \u001b[38;5;66;03m# Using python's default protocol to optimize compatibility.\u001b[39;00m\n\u001b[0;32m    517\u001b[0m         \u001b[38;5;66;03m# Otherwise cloudpickle uses latest protocol leading to incompatibilities.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m         \u001b[38;5;66;03m# See https://github.com/mlflow/mlflow/issues/5419\u001b[39;00m\n\u001b[1;32m--> 519\u001b[0m         \u001b[43mpickle_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43msk_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEFAULT_PROTOCOL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (pickle\u001b[38;5;241m.\u001b[39mPicklingError, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    521\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m sk_model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _gen_estimators_to_patch():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\OC_ML_PRJ_5\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py:55\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol, buffer_callback)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, buffer_callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;124;03m\"\"\"Serialize obj as bytes streamed into file\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m    protocol defaults to cloudpickle.DEFAULT_PROTOCOL which is an alias to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m    compatibility with older versions of Python.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m     \u001b[43mCloudPickler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer_callback\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\OC_ML_PRJ_5\\lib\\site-packages\\cloudpickle\\cloudpickle_fast.py:632\u001b[0m, in \u001b[0;36mCloudPickler.dump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj):\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecursion\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\OC_ML_PRJ_5\\lib\\site-packages\\google\\protobuf\\internal\\containers.py:243\u001b[0m, in \u001b[0;36mRepeatedScalarFieldContainer.__reduce__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__reduce__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m--> 243\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mPickleError(\n\u001b[0;32m    244\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle repeated scalar fields, convert to list first\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mPickleError\u001b[0m: Can't pickle repeated scalar fields, convert to list first"
     ]
    }
   ],
   "source": [
    "mlflow.sklearn.save_model(pipe, 'mlflow_model', signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ecdbc4-b414-4d6c-b7e1-939bd7cebdab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
