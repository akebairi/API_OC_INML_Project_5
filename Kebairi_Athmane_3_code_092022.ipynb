{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb04448d-9cb2-4f56-b174-24592edab520",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h1>Projet_OC_05 : Catégorisez automatiquement des questions (API)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8462dd8-d1e0-42be-82cb-7d550ad72db5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sommaire :\n",
    "\n",
    "**Partie 1 : Configuration du notebook**\n",
    "\n",
    " - <a href=\"#C11\">P1.1 : Chargement des librairies </a>\n",
    " - <a href=\"#C12\">P1.2 : Fonctions </a>\n",
    " - <a href=\"#C13\">P1.3 : Classes </a>\n",
    " - <a href=\"#C14\">P1.4 : Chargement des données</a>\n",
    " \n",
    "**Partie 2 : Modèle est déploiement**\n",
    "\n",
    " - <a href=\"#C21\">P2.1 : Structure de données </a>\n",
    " - <a href=\"#C22\">P2.2 : NaN et doublons </a>\n",
    " - <a href=\"#C23\">P2.3 : Inspection de données </a> \n",
    " \n",
    "**Partie 3 : Analyse de données**\n",
    "\n",
    " - <a href=\"#C31\">P3.1 : Structure de données </a>\n",
    " - <a href=\"#C32\">P3.2 : Nettoyage de données </a>\n",
    " - <a href=\"#C33\">P3.3 : Visualisation par wordcloud </a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b236f59f-6ba4-4943-bdc9-2e710b5b1b42",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<h1>Partie 1 : Configuration du notebook</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcfa272-9ea7-4a7d-9a47-b2d7614c78b9",
   "metadata": {},
   "source": [
    "# <a name=\"C11\"> P1.1 : Chargement des librairies </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "4f7e1fe1-b89b-41cc-b419-03904c8f9ef8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, wordpunct_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import spacy\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression, Perceptron\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score, jaccard_score, recall_score, accuracy_score\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import joblib\n",
    "from mlflow.models.signature import infer_signature\n",
    "import mlflow.sklearn \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beacdf4e-5f6b-46d7-809b-68e60115a160",
   "metadata": {},
   "source": [
    "**La liste des librairies ci-dessus sont chargées.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71462af7-6fb3-49c0-92f5-ce91887424da",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <a name=\"C12\"> P1.2 : Fonctions </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "55a030ba-fb61-4af8-a478-3641be4498d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(scores, y_test, y_pred, clf, average='weighted'):\n",
    "\n",
    "    score_1 = accuracy_score(y_test, y_pred)\n",
    "    score_2 = recall_score(y_test, y_pred, average=average)\n",
    "    score_3 = f1_score(y_pred, y_test, average=average)\n",
    "    score_4 = jaccard_score(y_test, y_pred, average=average)\n",
    "\n",
    "\n",
    "    print(\"Clf: \", clf.__class__.__name__)\n",
    "    print(\"accuracy_score: {}\".format(score_1))\n",
    "    print(\"recall_score: {}\".format(score_2))\n",
    "    print(\"f1_score: {}\".format(score_3))\n",
    "    print(\"Jacard score: {}\".format(score_4))\n",
    "\n",
    "    scores_temp = np.concatenate((scores, np.around([score_1, score_2, score_3, score_4], 2)))\n",
    "\n",
    "    return scores_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "962a81f4-2747-46cb-9137-11c020b43977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags_process(sentence, most_freq_tags):\n",
    "    \n",
    "    sentence_process = (sentence.replace('<', ' ').replace('>', ' ').replace('/', ' ').strip()).split()\n",
    "    \n",
    "    sentence_filter = [word for word in sentence_process if word in most_freq_tags]                \n",
    "    \n",
    "    if sentence_filter:\n",
    "        return ' '.join(sentence_filter)\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c381d916-13c5-4902-972e-ebec054f6fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_ponc_process(sentence):\n",
    "    \n",
    "    return sentence.replace('c#', 'csharp').replace('c++', 'cplusplus').replace('.net', 'dotnet').replace('objective-c', 'objectivec').replace('ruby-on-rails', 'rubyonrails')\\\n",
    "                .replace('sql-server', 'sqlserver').replace('node.js', 'nodedotjs').replace('aspdotnet-mvc', 'aspdotnetmvc').replace('visual-studio', 'visualstudio').replace('visual studio', 'visualstudio')\\\n",
    "                .replace('unit-testing', 'unittesting').replace('cocoa-touch', 'cocoatouch').replace('python-3.x', 'python3x').replace('entity-framework', 'entityframework')\\\n",
    "                .replace('language-agnostic', 'languageagnostic').replace('amazon-web-services', 'amazonwebservices').replace('google-chrome', 'googlechrome').replace('user-interface', 'userinterface')\\\n",
    "                .replace('design-patterns', 'designpatterns').replace('version-control', 'versioncontrol').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8d21b4b1-5066-495e-a22d-283a7e068ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_tag_ponc_process(sentence):\n",
    "    \n",
    "    return sentence.replace('csharp', 'c#').replace('cplusplus', 'c++').replace('dotnet', '.net').replace('objectivec', 'objective-c').replace('rubyonrails', 'ruby-on-rails')\\\n",
    "                .replace('sqlserver', 'sql-server').replace('nodedotjs', 'node.js').replace('aspdotnetmvc', 'aspdotnet-mvc').replace('visualstudio', 'visual-studio')\\\n",
    "                .replace('unittesting', 'unit-testing').replace('cocoatouch', 'cocoa-touch').replace('python3x', 'python-3.x').replace('entityframework', 'entity-framework')\\\n",
    "                .replace('languageagnostic', 'language-agnostic').replace('amazonwebservices', 'amazon-web-services').replace('googlechrome', 'google-chrome').replace('userinterface', 'user-interface')\\\n",
    "                .replace('designpatterns', 'design-patterns').replace('versioncontrol', 'version-control').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4c3acd70-09c8-4fc7-accc-ef046b4e6516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_process(sentence, stop_words, authorized_pos, no_pos_tag_list, no_lem_stem_list, force_is_alpha=False, method='spacy', lem_or_stem='lem'):\n",
    "    \n",
    "    sentence_lower = sentence.lower()\n",
    "    \n",
    "    sentence_no_html_raw = BeautifulSoup(sentence_lower, \"html.parser\")\n",
    "\n",
    "    for data in sentence_no_html_raw(['style', 'script', 'code', 'a']):\n",
    "        # Remove tags\n",
    "        data.decompose()\n",
    "        \n",
    "    sentence_no_html = ' '.join(sentence_no_html_raw.stripped_strings)\n",
    "    \n",
    "    sentence_no_abb = sentence_no_html.replace(\"what's\", \"what is \").replace(\"\\'ve\", \" have \").replace(\"can't\", \"can not \").replace(\"n't\", \" not \").replace(\"i'm\", \"i am \")\\\n",
    "                       .replace(\"\\'re\", \" are \").replace(\"\\'d\", \" would \").replace(\"\\'ll\", \" will \").replace(\"\\'scuse\", \" excuse \").replace(' vs ', ' ').replace('difference between', ' ')\n",
    "\n",
    "    sentence_no_abb_trans = tag_ponc_process(sentence_no_abb)\n",
    "\n",
    "    sentence_no_new_line = re.sub(r'\\n', ' ', sentence_no_abb_trans)\n",
    "\n",
    "    translator = str.maketrans(dict.fromkeys(string.punctuation, ' '))\n",
    "    sentence_no_caracter = sentence_no_new_line.translate(translator)\n",
    "    \n",
    "    sentence_no_stopwords = ' '.join([word for word in sentence_no_caracter.split() if word not in stop_words])\n",
    "    \n",
    "    if method=='word':\n",
    "        tokens_list = word_tokenize(sentence_no_stopwords)\n",
    "        sentence_tokens = [word for (word, tag) in nltk.pos_tag(tokens_list) if tag in authorized_pos and len(word)>=3 or word in no_pos_tag_list] \n",
    "    elif method=='wordpunct':\n",
    "        tokens_list = wordpunct_tokenize(sentence_no_stopwords)\n",
    "        sentence_tokens = [word for (word, tag) in nltk.pos_tag(tokens_list) if tag in authorized_pos and len(word)>=3 or word in no_pos_tag_list]\n",
    "    elif method=='spacy':\n",
    "        sentence_tokens =  [token.text for token in nlp(sentence_no_stopwords) if token.tag_ in authorized_pos and len(token.text)>=3 or token.text in no_pos_tag_list] \n",
    "    else: \n",
    "        tokens_list = RegexpTokenizer(r\"\\w+\").tokenize(sentence_no_stopwords)\n",
    "        sentence_tokens = [word for (word, tag) in nltk.pos_tag(tokens_list) if tag in authorized_pos and len(word)>=3 or word in no_pos_tag_list]\n",
    "    \n",
    "    if force_is_alpha:\n",
    "        alpha_tokens = [word for word in sentence_tokens if word.isalpha()]\n",
    "    else:\n",
    "        alpha_tokens = sentence_tokens\n",
    "    \n",
    "    if lem_or_stem=='lem':\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lem_or_stem_tokens = [lemmatizer.lemmatize(word) if word not in no_lem_stem_list else word for word in alpha_tokens]\n",
    "        \n",
    "    else:\n",
    "        stemmer = PorterStemmer()\n",
    "        lem_or_stem_tokens = [stemmer.stem(word) if word not in no_lem_stem_list else word for word in alpha_tokens]\n",
    "    \n",
    "    final_sentence = inverse_tag_ponc_process(' '.join(sentence_tokens))\n",
    "    \n",
    "    return final_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "51566532-a917-4678-87e8-7a5fdd9ed63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_USE_fct(sentences, b_size) :\n",
    "    batch_size = b_size\n",
    "    time1 = time.time()\n",
    "\n",
    "    for step in range(len(sentences)//batch_size) :\n",
    "        idx = step*batch_size\n",
    "        feat = embed(sentences[idx:idx+batch_size])\n",
    "\n",
    "        if step ==0 :\n",
    "            features = feat\n",
    "        else :\n",
    "            features = np.concatenate((features,feat))\n",
    "\n",
    "    time2 = np.round(time.time() - time1,0)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640cf9a2-2850-48c8-964a-681d4315a1a5",
   "metadata": {},
   "source": [
    "# <a name=\"C13\"> P1.3 : Classes </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c14ccb1d-babf-4c60-a2f0-145258a8b59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TXTModel(TransformerMixin, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, clf, ml_binarizer):\n",
    "        self.clf = clf\n",
    "        self.ml_binarizer = ml_binarizer\n",
    "        \n",
    "    def transform(self, Y):\n",
    "        \n",
    "        return self.ml_binarizer.transform(Y.tolist()) \n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        \n",
    "        self.ml_binarizer.fit(Y.tolist())\n",
    "        self.clf.fit(X, self.ml_binarizer.transform(Y.tolist()))\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \n",
    "        dfun = self.clf.decision_function(X)\n",
    "        most_common_idx = dfun.argsort()[:, -5:]\n",
    "        return self.classes_(most_common_idx)\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "\n",
    "        return self.clf.decision_function(X)    \n",
    "    \n",
    "    def classes_(self, Y_idx):\n",
    "        \n",
    "        return self.ml_binarizer.classes_[Y_idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b238cb73-68e7-4719-86f7-abfaac666530",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <a name=\"C14\"> P1.4 : Chargement des données </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "58ff71e9-3bcd-4cd3-9d03-a1a9e3fd4b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Data size: (99997, 3)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Find Mime type of file or url using php for al...</td>\n",
       "      <td>&lt;p&gt;Hi I am looking for best way to find out mi...</td>\n",
       "      <td>&lt;php&gt;&lt;amazon-web-services&gt;&lt;mime-types&gt;&lt;content...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>native zlib inflate/deflate for swift3 on iOS</td>\n",
       "      <td>&lt;p&gt;I'd like to be able to inflate/deflate Swif...</td>\n",
       "      <td>&lt;ios&gt;&lt;swift&gt;&lt;swift3&gt;&lt;zlib&gt;&lt;swift-data&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>`Sudo pip install matplotlib` fails to find fr...</td>\n",
       "      <td>&lt;p&gt;I already have &lt;code&gt;matplotlib-1.2.1&lt;/code...</td>\n",
       "      <td>&lt;python&gt;&lt;numpy&gt;&lt;matplotlib&gt;&lt;homebrew&gt;&lt;osx-mave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Serialization in C# without using file system</td>\n",
       "      <td>&lt;p&gt;I have a simple 2D array of strings and I w...</td>\n",
       "      <td>&lt;c#&gt;&lt;sharepoint&gt;&lt;serialization&gt;&lt;moss&gt;&lt;wss&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do I prevent IIS from compiling website?</td>\n",
       "      <td>&lt;p&gt;I have an ASP .NET web application which on...</td>\n",
       "      <td>&lt;asp.net&gt;&lt;performance&gt;&lt;web-services&gt;&lt;iis&gt;&lt;asmx&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Find Mime type of file or url using php for al...   \n",
       "1      native zlib inflate/deflate for swift3 on iOS   \n",
       "2  `Sudo pip install matplotlib` fails to find fr...   \n",
       "3      Serialization in C# without using file system   \n",
       "4       How do I prevent IIS from compiling website?   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <p>Hi I am looking for best way to find out mi...   \n",
       "1  <p>I'd like to be able to inflate/deflate Swif...   \n",
       "2  <p>I already have <code>matplotlib-1.2.1</code...   \n",
       "3  <p>I have a simple 2D array of strings and I w...   \n",
       "4  <p>I have an ASP .NET web application which on...   \n",
       "\n",
       "                                                Tags  \n",
       "0  <php><amazon-web-services><mime-types><content...  \n",
       "1             <ios><swift><swift3><zlib><swift-data>  \n",
       "2  <python><numpy><matplotlib><homebrew><osx-mave...  \n",
       "3         <c#><sharepoint><serialization><moss><wss>  \n",
       "4    <asp.net><performance><web-services><iis><asmx>  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_txt_data = pd.read_csv('data.csv')\n",
    "raw_txt_data = raw_txt_data.select_dtypes(include=object)\n",
    "raw_txt_data.dropna(inplace=True)\n",
    "\n",
    "print('-'*150)\n",
    "print('Data size:', raw_txt_data.shape)\n",
    "print('-'*150)\n",
    "raw_txt_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbc8d06-2a30-45c7-a806-f27360aa4f3f",
   "metadata": {},
   "source": [
    "**Ci-dessus, les données originales sont chargées.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a682db-c27a-4bbe-8d05-c7e4426591cf",
   "metadata": {},
   "source": [
    "<h1>Partie 2 : Modèle est déploiement</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6de190-8141-4656-9ea8-22dc3c4a6a21",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <a name=\"C21\"> P2.1 : Modèle </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "2fce1b45-3b8e-4fff-8d74-02c10b557ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_val = 50\n",
    "all_tags = ' '.join(raw_txt_data.Tags.apply(lambda sentence: sentence.replace('<', ' ').replace('>', ' ')).tolist()).split()\n",
    "unique_tags = list(set(all_tags))\n",
    "keywords = nltk.FreqDist(all_tags)\n",
    "most_common_tags = [word[0] for word in keywords.most_common(most_common_val)]\n",
    "\n",
    "raw_txt_data['Tags'] = raw_txt_data.Tags.apply(lambda sentence: tags_process(sentence, most_common_tags))\n",
    "raw_txt_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfab81a-2909-42cb-bdf4-da8bbe4ddd98",
   "metadata": {},
   "source": [
    "**La variable \"Tags\" est nétoyée et filtrée: 50 tags les plus fréquents sont uniquement gardés.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "86e92540-6ba9-4009-a636-baade5686256",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "authorized_pos = ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "no_pos_tag_list = tag_ponc_process(' '.join(most_common_tags)).split()\n",
    "no_lem_stem_list = tag_ponc_process(' '.join(most_common_tags)).split()\n",
    "stop_words = list(set(stopwords.words('english'))) + \\\n",
    "                ['[', ']', ',', '.', ':', '?', '(', ')']\n",
    "stop_words.extend(['good', 'idea', 'solution', 'issue', 'problem', 'way', 'example', 'case', 'question', 'questions', 'something', 'everything',\n",
    "                   'anything', 'thing', 'things', 'answer', 'thank', 'thanks', 'none', 'end', 'anyone', 'test', 'lot', 'one', 'someone', 'help'])\n",
    "\n",
    "clf = OneVsRestClassifier(LinearSVC())\n",
    "ml_binarizer = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37a4d47-adb1-4c8a-ad9c-1a3003553540",
   "metadata": {},
   "source": [
    "**La définition des variables du modèle est faite ci-dessus.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "9cb0190e-149f-42b7-9a1b-d8540edefc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ME\\anaconda3\\envs\\OC_ML_PRJ_5\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "raw_txt_data['Title_Body'] = raw_txt_data['Title'] + ' ' + raw_txt_data['Body']\n",
    "\n",
    "X = raw_txt_data['Title_Body'].apply(lambda sen: txt_process(sen, stop_words, authorized_pos, no_pos_tag_list, no_lem_stem_list))\n",
    "y = pd.Series(raw_txt_data.Tags.values, index=raw_txt_data.Tags.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a51645-9915-4d31-be2a-3ed0e2bece4b",
   "metadata": {},
   "source": [
    "**Test processing et création des variables X, y.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f0f00b76-66e2-485d-8545-785fc0ff73ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_norm = 8\n",
    "X_use = feature_USE_fct(X, idx_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e761f3-113b-4009-977c-2f4fc8272024",
   "metadata": {},
   "source": [
    "**Création des features USE est faite ci-dessus.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "e03d6eeb-6c04-4960-9756-7e0f13ac33db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_use, y[:(len(X_use)//idx_norm)*idx_norm], test_size = 0.25, random_state = 1) \n",
    "\n",
    "X_train = X_train[:(len(X_train)//idx_norm)*idx_norm]\n",
    "X_test = X_test[:(len(X_test)//idx_norm)*idx_norm]\n",
    "y_train = y_train[:(len(y_train)//idx_norm)*idx_norm]\n",
    "y_test = y_test[:(len(y_test)//idx_norm)*idx_norm]\n",
    "\n",
    "y_train = y_train.apply(lambda x: x.split())\n",
    "y_test = y_test.apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101bc366-2855-4ec1-b4fc-284ed06255bd",
   "metadata": {},
   "source": [
    "**Split des variable X, y.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "1b36c426-7a28-4cc4-9f7a-d2dd7739c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = TXTModel(clf, ml_binarizer)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c4a611-d443-4ae0-90f5-ecb627d04453",
   "metadata": {},
   "source": [
    "**Ci-dessus, fitting du modèle.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ead9b81e-607b-4075-8908-e2eedc884ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clf:  TXTModel\n",
      "accuracy_score: 0.0004152823920265781\n",
      "recall_score: 0.2968069398301956\n",
      "f1_score: 0.4475522529292254\n",
      "Jacard score: 0.2882881267815206\n"
     ]
    }
   ],
   "source": [
    "ml_binarizer_score = MultiLabelBinarizer()\n",
    "ml_binarizer_score.fit(y_train)\n",
    "scores = print_score([], ml_binarizer_score.transform(clf.predict(X_test)), ml_binarizer_score.transform(y_test), clf, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba7c40a-3bed-4b3b-ac32-12399ec14ca5",
   "metadata": {},
   "source": [
    "**Le score du modèle est donné ci-dessus. Le score est inférieur, car obtenu avec la méthode \"decision_function\" en considérant les 5 premiers Tags.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7c4b97-8c27-4409-a3da-6670bef8bd94",
   "metadata": {},
   "source": [
    "# <a name=\"C22\"> P2.2 : déploiement du modèle (mlflow)</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "664108c6-4967-4b4d-81d7-04e13b4ec476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clf_housing.joblib']"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, 'clf_housing.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff73d466-82dc-4f87-8488-86a0ca3c3dfb",
   "metadata": {},
   "source": [
    "**Sérialisation du modèle à l'aide de joblib.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "6b865cb2-a7ae-48ae-b448-e9a1338bfb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature = infer_signature(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9100e13-4816-4bf3-b1d0-80545370b8ea",
   "metadata": {},
   "source": [
    "**Extraction de la signature de données d'entrée et de sortie.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "87c578e7-080c-4a7e-a6d1-6cbf60b667e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.sklearn.save_model(clf, 'mlflow_model', signature=signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7359b300-e29d-49f4-b519-7e721cb7a0c7",
   "metadata": {},
   "source": [
    "**Le modèle \"clf\" est sauvegardé à l'aide de la fonction save_model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b41896-b661-4ce9-a7a4-fbdf865add3d",
   "metadata": {},
   "source": [
    "mlflow models serve -m mlflow_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532da0af-df48-4186-a930-e2443657e2b7",
   "metadata": {},
   "source": [
    "**Une API REST (mlflow) est créée.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
